---
layout: post
title: anoGAN(Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery)
tags: [Test, Markdown]
---

## Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery
![AnoGAN Paper](https://github.com/uk-kim/uk-kim.github.io/blob/master/_posts/2019-01-06-anoGAN/anogan_paper.png?raw=true)

이 논문은 2017년에 공개된 논문으로써 DCGAN을 적용하여 이상감지, 의료 영상에서 이상 영역 감지 등의 분야의 문제를 해결하는 방법을 소개한다.

---
### Abstract
모델들은 검출 자동화를 목표로 알려진 marker를 토대로 주석이 달려진 많은 양의 데이터를 기반으로 만들어진다. 많은 Annotation의 노력과 알고있는 마커의 종류 한계는 이러한 접근 방법의 power를 제한한다. 우리는 이미지 데이터의 이상을 마커의 후보로써 확인하기 위해 비교사 학습방법을 수행한다. 우리는 DCGAN을 통해 정상 anatomical variability의 manifold를 학습하고, 이미지 공간에서 latent 공간으로의 맵핑을 기반으로한 anomaly scoring를 동반하는 AnoGAN을 제안한다.

### 1. Introduction
많은 질병들은 충분한 데이터 셋이 부족한 반면, 다른 질병들은 마커의 예측력이 제한적이다. 또한, 예측가능한 마커를 알더라도, 영상 데이터에서 검출은 일반적으로 라벨이 되어있는 많은 양의 데이터를 토대로 광범위한 지도학습이 필요하다. 이는 치료 결정을 위한 이미지 데이터를 활용하는 우리의 능력을 제한한다. 우리는 건강한 국부 해부학적 외관의 풍부한 생성 모델을 생성하기 위해 비교사 학습을 제안한다.

우리는 이미지 space에서 latent space로의 맵핑을을 위한 진보된 기법을 제안한다. 우리는 학습 데이터를 따르는 관측치와 이에 적합하지 않는 데이터를 구분하기 위해 두 요소를 모두 사용한다.


이 논문의 기여는, 우리는 비정상 이미지를 식별하고 이미지 데이터의 비정상 영역을 구분(Fig.2 red box)하기 위해 새로운 데이터를 평가할 수 있게하는 정상 모양의 생성 모델과 결합된 맵핑 스키마 대립 학습(Fig.1 blue box)을 제안한다.

![AnoGAN fig1](https://github.com/uk-kim/uk-kim.github.io/blob/master/_posts/2019-01-06-anoGAN/anogan_fig1.png?raw=true)

### 2. Generative Adversarial Representation Learning to Identify Anomalies
이상 감지를 위해, 우리는 GAN 기반의 정상 해부학적 가변성을 표현하는 모델을 학습한다.

이러한 방법은 생성모델과, 생성된 데이터와 실제 데이터를 동시에 구분하는 discriminator를 학습시킨다.

단일 비용 함수 최적화 대신, 비용의 내쉬 균형, 생성 모델의 대표성과 특이성을 높이는 동시에 생성된 데이터로부터 실제 데이터를 더 정확하게 분류하고 대응하는 Feature Mapping을 개선하는 것을 목표로 한다.

다음으로 우리는 어떻게 이 모델을 만들고, 이 모델을 사용해서 어떻게 학습 데이터에 나타나지 않은 형태를 식별하는지에 대해서 설명한다.

![AnoGAN fig2](https://github.com/uk-kim/uk-kim.github.io/blob/master/_posts/2019-01-06-anoGAN/anogan_fig2.png?raw=true)
#### 2.1 Unsupervised Manifold Learning of Normal Anatomical Variability

$$$m = 1, 2, ..., M$$$이고, $$$I_m \in \mathbb{R}^{a \times b}$$$가 $$$a \times b$$$ 크기의 밝기 이미지일 때, 건강한 해부학 의료 이미지 $$$I_m$$$으로 이루어진 $M$개의 집합이 있다.
각 $$$I_m$$$ 이미지로부터 무작위로 샘플링된 위치에서 데이터 $$$\mathbf{x}=x_{k,m}\in \mathcal{X}$$$를 얻는다. 이때, $$$k=1,2,...,K$$$.
훈련 도중에 우리는 유일하게 $$$\langle I_m \rangle$$$만 제공되고, 학습 이미지의 가변성을 나타내는 manifold $$$\mathcal{X}$$$(Fig.2(b) blue region)를 배우기 위해 생성 대립 모델을 훈련시킨다.

테스트를 위해, 테스트 데이터 $$$\mathbf{J}$$$와 이진 라벨 Ground Truth $$$l_n \in \{0, 1\}$$$로부터 추출된 $$$c \times c$$$ 크기의 알지 못하는 이미지를 $$$\mathbf{y}_n$$$이라 할 때, $$$\langle \mathbf{y}_n, l_n \rangle$$$가 주어진다.
이러한 라벨은 주어진 병리학 기반의 이상 감지 성능 평가를 위한 테스트 중에만 주어진다.

<i><b>Encoding Anatomical Variability with a Generative Adversarial Network.</b></i>
GAN은 두개의 대립하는 모듈로 구성되어 있는데, 생성자 $G$와 구분자 $D$로 이루어져있다.
생성자 $G$ 는 latent space $\mathcal{Z}$로부터 샘플링된 입력 노이즈의 uniform 분포로 이루어진 1차원 벡터인 샘플 $\mathbf{z}$를 $G(\mathbf{z})$를 잘 알려진 건강한 예제로 구성된 이미지 space manifold $\mathcal{X}$의 2D 이미지로 맵핑하기 위해 데이터 $\mathbf{x}$를 따르는 분포 $p_g$를 배운다.

여기에서 생성자 $G$의 네트워크 구조가 strided convolutions(same as deconvolution ..)가 쌓인 convolutional decoder와 같은 구조를 갖는다. 구분자 $D$는 2차원 이미지를 단일 scalar 값 $D(\cdot)$으로 변환하는 일반적인 CNN 이다. 구분자의 출력 $D(\cdot)$은 구분자 $D$의 입력이 학습 데이터 $\mathcal{X}$를 따르는 실제 이미지 $\mathbf{x}$인지 또는 생성자 $G$를 통해 생성된 $G(\mathbf{z})$인지에 대한 확률로써 변환될 수 있다.
$D$와 $G$는 아래와 같은 함수값 $V(G, D)$에 대한 two-player minimax game를 통해 동시에 최적화 된다:

$$
\underset{G}{\min}\underset{D}{\max}V(D, G)=\mathbb{E}_{\mathbf{x}\sim p_{data}}
[\log{D(\mathbf{x})}]+\mathbb{E}_{\mathbf{z}\sim p_{\mathbf{z}}(\mathbf{z})}[\log{(1-D(G(\mathbf{z})))}]
$$


#### 2.2 Mapping new Images to the Latent space
adversarial training이 완료되면, 생성자는 $G(\mathbf{x})=\mathbf{x}\longmapsto \mathbf{z}$의 맵핑 관계(latent space representation $\mathbf{z}$로부터 realistic image $\mathbf{x}$)를 학습이 되었다. 하지만 GAN은 반대의 맵핑 관계($\mu(\mathbf{x})=\mathbf{x}\longmapsto \mathbf{z}$)는 일반적으로 알 수 없다. Latent Space는 Smooth한 transition을 갖고 있기 때문에, latent space 상의 인접한 두 점으로 부터 생성자를 통해 생성된 두 이미지는 유사하게 된다. 따라서 쿼리이미지 $\mathbf{x}$가 주어지면, 우리는 manifold $\mathcal{X}$에 위치하며, 쿼리이미지 $\mathbf{x}$와 가장 유사한 $G(\mathbf{z})$에 대응하는 latent space의 $\mathbf{z}$를 찾고자 한다. $\mathbf{x}$와 $G(\mathbf{z})$의 유사도는 생성자를 학습할 때의 데이터 분포 $P_g$를 $\mathbf{x}$가 얼마나 따르는지에 의해 결정된다.
최적의 $\mathbf{z}$를 찾기 위해서, latent space의 분포 $\mathcal{Z}$로부터 $\mathbf{z_1}$을 random sampling하여 $G(\mathbf{z})$를 생성한다. 이후 $G=(\mathbf{z})$를 토대로 loss function을 설정하고, loss function의 gradient를 계산하여 $\mathbf{z_2}$를 찾는다. 쿼리이미지 $\mathbf{x}$와 가장 유사한 $G(\mathbf{z_{\mathcal{T}}})$를 찾기 위해 이를 반복한다.

loss function은 <b>Residual Loss</b>와 <b>Discrimination Loss</b> 두가지로 구성되어 있다.
Residual Loss는 $G(\mathbf{z_{\gamma}})$와 쿼리이미지 $\mathbf{x}$가 유사하게 나타나게 한다. 그리고 Discrimination Loss는 $G(\mathbf{z_{\gamma}})$가 학습된 Manifold $\mathcal{X}$에 위치하게 한다.

<b>Residual Loss</b> : measures the visual dissimilarity between query image $\mathbf{x}$ and generated image $G(\mathbf{z_{\gamma}})$ in the image Space

$$
\mathcal{L_R}(\mathbf{z}_\gamma)=\sum{\vert \mathbf{x} - G(\mathbf{z}_\gamma) \vert}
$$

생성자가 완벽하게 latent space로의 맵핑이 되어있다면, 이때 Residual Loss는 0을 갖게 될 것임.

<b>An improved discrimination loss based on feature matching</b>
생성자는 학습데이터의 분포와 유사하게끔 데이터를 생성하게 된다. 이때 내부의 중간 Feature는 실제 이미지의 Feature와 유사하다. 이러한 성질을 이용하여 latent space로의 mapping을 향상시키기 위해 feature mapping을 이용한다. Discriminator의 출력인 스칼라 값을 가지고 Discrimination loss를 계산하는 대신에 discriminator의 보다 풍부한 정보를 포함하고 있는 중간의 feature로써 discrimination loss를 정의한다.

$$
\mathcal{L}_D(\mathbf{z}_\gamma)=\sum \vert \mathbf{f}(\mathbf{x}) - \mathbf{f}(G(\mathbf{z}_\gamma)) \vert
$$

$f(\cdot)$은 discriminator의 중간 layer의 출력을 의미하며, 이는 입력된 이미지의 특징을 담고 있다.

<br>
이미지를 latent space로 맵핑하기 위해서, 위 두 Loss Function을 적절한 가중합으로써 통합한 하나의 Loss로 정의한다.

$$
\mathcal{L} (\mathbf{z}_\gamma) =
(1 - \lambda) \cdot \mathcal{L}_R (\mathbf{z}_\gamma) +
\lambda \cdot \mathcal{L}_D (\mathbf{z}_\gamma)
$$

#### 2.3 Detection of anomalies
이미지를 latent space에 맵핑하는 데에 사용한 loss function $\mathcal{L}(\mathbf{z}_\gamma)$을 통해 매 update iteration $\gamma$마다 생성된 이미지 $G(\mathbf{z}_\gamma)$에 대한 적합성을 계산한다.
쿼리 이미지 $\mathbf{x}$가 모델의 정상 이미지에 적합한지를 표현하는 <b>anomaly score</b>는 맵핑 loss fucntion $\mathcal{L}(\mathbf{z}_\gamma)$로부터 직접 결정된다.
$$
A(\mathbf{x}) = (1-\lambda) \cdot R(\mathbf{x}) + \lambda \cdot D(\mathbf{x})
$$

$A(\mathbf{x})$ : Anomaly score
$R(\mathbf{x})$ : 마지막 iteration에서의 Residual Loss
$D(\mathbf{x})$ : 마지막 iteration에서의 Discriminator Loss

### 3. Experiments
#### 3.1 Results
![AnoGAN fig3](https://github.com/uk-kim/uk-kim.github.io/blob/master/_posts/2019-01-06-anoGAN/anogan_fig3.png?raw=true)


![AnoGAN fig4](https://github.com/uk-kim/uk-kim.github.io/blob/master/_posts/2019-01-06-anoGAN/anogan_fig4.png?raw=true)

### 4. Conclusion
